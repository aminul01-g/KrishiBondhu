# Chat History Enhancement - Continuous Conversation Support

## Problem
The chatbot was not remembering or referencing previous chat history. Each query was treated in isolation, making it unable to provide continuous assistance across multiple turns.

**Example of the issue:**
```
Turn 1: User: "My rice has brown spots"
Bot: "This could be a rice blast disease. Try..."

Turn 2: User: "Should I use pesticides?"
Bot: "Could you tell me what crop you're growing?"  ‚ùå Forgot about rice!
```

## Solution
Enhanced the `/api/chat` endpoint to:
1. ‚úÖ Load previous conversation history from database
2. ‚úÖ Include relevant past conversations in the LLM context
3. ‚úÖ Enable the AI to reference and build upon previous answers
4. ‚úÖ Maintain language awareness across conversations

## How It Works

### Step 1: User Sends Chat Message
```json
POST /api/chat
{
  "message": "Should I use pesticides?",
  "user_id": "farmer123",
  "include_history": true
}
```

### Step 2: Load Chat History
```python
# Query database for last 5 conversations for this user
SELECT * FROM conversations 
WHERE user_id = 'farmer123'
ORDER BY created_at DESC 
LIMIT 5
```

### Step 3: Build Message Context
```python
messages = [
  # Previous conversations (oldest to newest)
  {"role": "user", "content": "My rice has brown spots"},
  {"role": "assistant", "content": "This could be rice blast disease..."},
  
  # Current message (newest)
  {"role": "user", "content": "Should I use pesticides?"}
]
```

### Step 4: LLM Generates Response
The LLM receives full conversation context and can:
- ‚úÖ Reference the rice crop from Turn 1
- ‚úÖ Reference the brown spots diagnosis
- ‚úÖ Provide pesticide recommendations in context
- ‚úÖ Maintain conversation coherence

```
Turn 2 Response (NEW):
"Yes, for rice blast disease, I recommend using these pesticides:
1. Tricyclazole (most effective)
2. Propiconazole (alternative)
Since your rice has brown spots as we discussed, apply fungicide..."  ‚úÖ
```

## Files Modified

### 1. `/backend/app/main.py` - Chat Endpoint

**Changes:**
- Added `include_history` parameter (default: True)
- Added database dependency injection
- Added history loading logic before workflow execution
- Builds messages list with historical context

```python
@app.post('/api/chat')
async def chat(
    message: str = Form(...),
    user_id: str = Form(...),
    lat: float = Form(None),
    lon: float = Form(None),
    image: UploadFile = File(None),
    include_history: bool = Form(True),  # NEW!
    db: AsyncSession = Depends(get_db)
):
    # Load last 5 conversations for user
    # Build messages list with history
    # Pass to workflow
```

**Line numbers:** ~140-180

### 2. `/backend/app/farm_agent/langgraph_app.py` - System Instructions

**Changes:**
- Updated text/chat system instruction (lines 752-787)
- Changed from "ignore previous context" to "use history wisely"
- Added guidelines for when to use and when to ignore history
- Maintained language matching requirement

**Key Updates:**
```
OLD: "Do NOT reference, assume, or carry over context from previous messages"
NEW: "You have access to BOTH the current message AND previous chat history"
     "YOU SHOULD use chat history to provide CONTINUOUS, CONTEXT-AWARE assistance"
```

## API Changes

### Chat Endpoint Now Accepts

```
POST /api/chat
Content-Type: multipart/form-data

Parameters:
- message (required): Current user message
- user_id (required): Farmer's unique ID
- lat (optional): GPS latitude
- lon (optional): GPS longitude
- image (optional): Image file to analyze
- include_history (optional, default: true): Whether to load chat history
```

### Example Request

```bash
curl -X POST http://localhost:8000/api/chat \
  --form "message=Should I use pesticides for my rice?" \
  --form "user_id=farmer123" \
  --form "include_history=true"
```

## Conversation Flow Example

### Conversation Sequence

**Turn 1:**
```
User: "My rice crop has brown spots and yellow edges"
DB History: [empty]
Bot Response: "This appears to be rice blast disease..."
Saved: transcript + response in DB
```

**Turn 2:**
```
User: "What pesticide should I use?"
DB History: [Turn 1 Q & A]
Loaded Messages:
  [
    {"role": "user", "content": "My rice crop has brown spots..."},
    {"role": "assistant", "content": "This appears to be rice blast..."},
    {"role": "user", "content": "What pesticide should I use?"}
  ]
Bot Response: "For the rice blast disease on your rice, I recommend..."
Saved: Turn 2 transcript + response
```

**Turn 3:**
```
User: "How often should I spray?"
DB History: [Turn 1, Turn 2]
Loaded Messages: [All previous exchanges]
Bot Response: "For rice blast treatment, spray every 7-10 days..."
```

## Database Schema

### Conversation Table
```sql
CREATE TABLE conversations (
    id INTEGER PRIMARY KEY,
    user_id INTEGER,
    transcript TEXT,              -- User's question
    tts_path VARCHAR,
    media_url VARCHAR,
    confidence FLOAT,
    meta_data JSON,               -- Stores bot's reply_text here
    created_at TIMESTAMP
);
```

### Meta Data Structure
```json
{
    "reply_text": "This appears to be rice blast disease...",
    "crop": "rice",
    "language": "en",
    "vision_result": {},
    "weather_forecast": {}
}
```

## Technical Details

### History Loading Logic

1. **Query Database:**
   ```python
   result = await db.execute(
       select(Conversation)
       .where(Conversation.user_id == user_id)
       .order_by(desc(Conversation.created_at))
       .limit(5)
   )
   ```

2. **Reverse Order:**
   ```python
   previous_convs = list(reversed(previous_convs))
   # This ensures chronological order (oldest to newest)
   ```

3. **Build Messages:**
   ```python
   for conv in previous_convs:
       messages.append({"role": "user", "content": conv.transcript})
       if conv.meta_data.get("reply_text"):
           messages.append({"role": "assistant", "content": conv.meta_data["reply_text"]})
   ```

4. **Append Current:**
   ```python
   messages.append({"role": "user", "content": message})
   ```

### History Limits

- **Last 5 conversations loaded** - Balances context richness vs LLM token usage
- **Configurable:** Can change `limit(5)` to any number
- **User-specific:** Each `user_id` has separate history

### Error Handling

```python
try:
    # Load history
except Exception as e:
    print(f"Could not load history: {e}")
    # Continue without history - graceful fallback
    messages = [{"role": "user", "content": message}]
```

## System Instructions

### When to USE History

‚úÖ **DO reference previous conversations when:**
- Farmer is following up on earlier discussion
- Question asks about same crop/problem as before
- You need to provide continuous support
- User references something they mentioned before

**Example:**
```
User: "How do I prevent this in the future?"
Response: "To prevent the rice blast disease you've been experiencing, 
you should: 1) Improve drainage, 2) Use resistant varieties..."
```

### When to IGNORE History

‚ùå **DON'T reference history when:**
- Farmer asks about a completely different crop
- New image shows a different problem
- User explicitly asks for new topic
- Farmer asks "What crop should I grow?"

**Example:**
```
User: "What about tomatoes?"
Response: "Tomatoes require different care than rice. 
For tomato cultivation, you should..."
(Don't assume tomato disease is same as rice)
```

## Testing

### Test Continuous Conversation

```bash
# Turn 1: Ask about rice
curl -X POST http://localhost:8000/api/chat \
  --form "message=My rice has brown spots" \
  --form "user_id=test_farmer"

# Turn 2: Follow up (should remember rice)
curl -X POST http://localhost:8000/api/chat \
  --form "message=What pesticide should I use?" \
  --form "user_id=test_farmer"

# Check logs for:
# [DEBUG] /api/chat: Loaded 1 previous conversations for user test_farmer
```

### Disable History (if needed)

```bash
curl -X POST http://localhost:8000/api/chat \
  --form "message=Your question" \
  --form "user_id=test" \
  --form "include_history=false"  # Skip history
```

## Performance Considerations

- **Database Query:** O(log n) on indexed user_id
- **History Size:** 5 conversations √ó ~200 tokens = ~1000 extra tokens
- **LLM Cost:** Minimal impact (most LLMs process past messages efficiently)
- **Latency:** +10-50ms for database query (negligible)

## Backward Compatibility

‚úÖ **Fully backward compatible:**
- Old requests without `include_history` still work
- Default is `true` (history enabled)
- Can be disabled with `include_history=false`
- No breaking changes to API contract

## Future Enhancements

Possible improvements:
1. **Configurable history depth** - Let users choose how many turns to remember
2. **Summary-based history** - Summarize old turns to save tokens
3. **Topic detection** - Automatically recognize when user switches topics
4. **Memory prioritization** - Remember important solutions better
5. **User preferences** - Store whether user wants history or not

## Status

‚úÖ **IMPLEMENTED AND READY**

The chatbot now:
- ‚úÖ Loads previous conversation history
- ‚úÖ Maintains context across turns
- ‚úÖ Remembers crop/problem information
- ‚úÖ Provides continuous assistance
- ‚úÖ Handles history gaps gracefully
- ‚úÖ Still maintains language awareness
- ‚úÖ Follows all system guidelines

## How to Use

### For Continuous Conversations (DEFAULT)

Just use `/api/chat` normally - history is loaded automatically:

```bash
# Turn 1
curl -X POST http://localhost:8000/api/chat \
  --form "message=My rice has a disease" \
  --form "user_id=farmer123"

# Turn 2 - Bot remembers rice!
curl -X POST http://localhost:8000/api/chat \
  --form "message=What should I do?" \
  --form "user_id=farmer123"
```

### For Isolated Queries (disable history if needed)

```bash
curl -X POST http://localhost:8000/api/chat \
  --form "message=Your question" \
  --form "user_id=farmer123" \
  --form "include_history=false"
```

---

**Result: Users now have a continuous, context-aware chat experience! üéâ**
